{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import math\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "from typing import Optional, Tuple, Dict, List\n",
    "from tqdm import tqdm\n",
    "\n",
    "# import argparse\n",
    "import click\n",
    "import gtfparse\n",
    "import pandas as pd\n",
    "\n",
    "# import bisect\n",
    "\n",
    "# Global Variables\n",
    "version = 1.5\n",
    "\n",
    "NEWLINE = \"\\n\"\n",
    "TAB = \"\\t\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "version = 1.5\n",
    "CLASS_COLUMN_USED = [0, 1, 2, 3, 5, 6, 7, 28, 30, 31]\n",
    "CLASS_COLUMN_NAME = [\n",
    "    \"isoform\",\n",
    "    \"chrom\",\n",
    "    \"strand\",\n",
    "    \"length\",\n",
    "    \"structural_category\",\n",
    "    \"associated_gene\",\n",
    "    \"associated_transcript\",\n",
    "    \"ORF_length\",\n",
    "    \"CDS_start\",\n",
    "    \"CDS_end\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotation_file = \"/home/milo/workspace/Homo_sapiens_GRCh38_Ensembl_86.gff3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createGTFFromSqanti(\n",
    "    exons_gtf: str, transcript_classification: str, junctions: str\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\" Create a real GTF from the output of sqanti3_qc.\n",
    "\n",
    "    Params:\n",
    "    -------\n",
    "    exons_gtf : `str`\n",
    "    transcript_classification : `str`\n",
    "    junctions : `str`\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    :class:`~pandas.DataFrame`\n",
    "\n",
    "    \"\"\"\n",
    "    logger = logging.getLogger(\"IsoAnnotLite_SQ1\")\n",
    "    source = \"tappAS\"\n",
    "    aux = \".\"\n",
    "\n",
    "    logger.debug(f\"reading classification file {transcript_classification}\")\n",
    "    classification_df = pd.read_csv(transcript_classification, delimiter=\"\\t\")\n",
    "\n",
    "    CLASS_COLUMN_NAMES = [\n",
    "        \"isoform\",\n",
    "        \"chrom\",\n",
    "        \"strand\",\n",
    "        \"length\",\n",
    "        \"structural_category\",\n",
    "        \"associated_gene\",\n",
    "        \"associated_transcript\",\n",
    "        \"ORF_length\",\n",
    "        \"CDS_start\",\n",
    "        \"CDS_end\",\n",
    "    ]\n",
    "\n",
    "    missing_names = [\n",
    "        _ for _ in CLASS_COLUMN_NAMES if _ not in classification_df.columns\n",
    "    ]\n",
    "\n",
    "    if missing_names:\n",
    "        logger.info(\n",
    "            f\"File classification does not have the necessary fields. \"\n",
    "            f\"The columns {','.join(missing_names)} were not found in the \"\n",
    "            f\"in the classification file.\"\n",
    "        )\n",
    "        sys.exit()\n",
    "\n",
    "    # so, weird trick - it is *really* slow to append to a list or dataframe\n",
    "    # however, you can add on to a dictionary really quickly.\n",
    "    # also, you can easily convert a dictionary to a dataframe.\n",
    "    # so,\n",
    "    res = dict()\n",
    "    i = 0\n",
    "\n",
    "    # TODO: vectorize this\n",
    "    # add transcript, gene and CDS\n",
    "    for row in tqdm(classification_df.itertuples(), total=len(classification_df)):\n",
    "        # trans\n",
    "        transcript = row.isoform  # fields[0]\n",
    "        # source\n",
    "        feature = \"transcript\"\n",
    "        start = \"1\"\n",
    "        end = row.length  # fields[3]\n",
    "        # aux\n",
    "        strand = row.strand  # fields[2]\n",
    "\n",
    "        desc = f\"ID={row.associated_transcript}; primary_class={row.structural_category}{NEWLINE}\"  # desc = \"ID=\"+fields[7]+\"; primary_class=\"+fields[5]+\"\\n\"\n",
    "        res[i] = {\n",
    "            \"seqname\": transcript,\n",
    "            \"source\": source,\n",
    "            \"feature\": feature,\n",
    "            \"start\": str(int(start)),\n",
    "            \"end\": str(int(end)),\n",
    "            \"score\": aux,\n",
    "            \"strand\": strand,\n",
    "            \"frame\": aux,\n",
    "            \"attribute\": desc,\n",
    "        }\n",
    "\n",
    "        # gene\n",
    "        transcript = row.isoform\n",
    "        # source\n",
    "        feature = \"gene\"\n",
    "        start = \"1\"\n",
    "        end = row.length\n",
    "        # aux\n",
    "        strand = row.strand\n",
    "        desc = f\"ID={row.associated_gene};Name={row.associated_gene};Desc={row.associated_gene}{NEWLINE}\"\n",
    "\n",
    "        i += 1\n",
    "        res[i] = {\n",
    "            \"seqname\": transcript,\n",
    "            \"source\": source,\n",
    "            \"feature\": feature,\n",
    "            \"start\": str(int(start)),\n",
    "            \"end\": str(int(end)),\n",
    "            \"score\": aux,\n",
    "            \"strand\": strand,\n",
    "            \"frame\": aux,\n",
    "            \"attribute\": desc,\n",
    "        }\n",
    "\n",
    "        # CDS\n",
    "        transcript = row.isoform\n",
    "        # source\n",
    "        feature = \"CDS\"\n",
    "        start = row.CDS_start  # 30\n",
    "        end = row.CDS_end  # 31\n",
    "        # aux\n",
    "        strand = row.strand\n",
    "        desc = f\"ID=Protein_{transcript};Name=Protein_{transcript};Desc=Protein_{transcript}{NEWLINE}\"\n",
    "        if start != \"NA\" and not pd.isnull(start):\n",
    "            prot_length = int(math.ceil((int(end) - int(start) - 1) / 3))\n",
    "            i += 1\n",
    "            res[i] = {\n",
    "                \"seqname\": transcript,\n",
    "                \"source\": source,\n",
    "                \"feature\": feature,\n",
    "                \"start\": str(int(start)),\n",
    "                \"end\": str(int(end)),\n",
    "                \"score\": aux,\n",
    "                \"strand\": strand,\n",
    "                \"frame\": aux,\n",
    "                \"attribute\": desc,\n",
    "            }\n",
    "            i += 1\n",
    "            res[i] = {\n",
    "                \"seqname\": transcript,\n",
    "                \"source\": source,\n",
    "                \"feature\": \"protein\",\n",
    "                \"start\": \"1\",\n",
    "                \"end\": str(prot_length),\n",
    "                \"score\": aux,\n",
    "                \"strand\": strand,\n",
    "                \"frame\": aux,\n",
    "                \"attribute\": desc,\n",
    "            }\n",
    "\n",
    "            # res.write(\"\\t\".join([transcript,source, feature, str(int(start)), str(int(end)), aux, strand, aux, desc]))\n",
    "            # res.write(\"\\t\".join([transcript,source,\"protein\",\"1\",str(prot_length),aux,strand,aux,desc]))\n",
    "        # else:\n",
    "        # res.write(\"\\t\".join([transcript, source, feature, \".\", \".\", aux, strand, aux, desc]))\n",
    "\n",
    "        # genomic\n",
    "        desc = f\"Chr={row.chrom}{NEWLINE}\"\n",
    "\n",
    "        # Coding Dictionary\n",
    "        CDSstart = row.CDS_start  # 30\n",
    "        CDSend = row.CDS_end  # 31\n",
    "        orf = row.ORF_length  # 28\n",
    "\n",
    "        i += 1\n",
    "        res[i] = {\n",
    "            \"seqname\": transcript,\n",
    "            \"source\": source,\n",
    "            \"feature\": \"genomic\",\n",
    "            \"start\": \"1\",\n",
    "            \"end\": \"1\",\n",
    "            \"score\": aux,\n",
    "            \"strand\": strand,\n",
    "            \"frame\": aux,\n",
    "            \"attribute\": desc,\n",
    "        }\n",
    "\n",
    "        # Write TranscriptAttributes\n",
    "        sourceAux = \"TranscriptAttributes\"\n",
    "        lengthTranscript = row.length\n",
    "        if not CDSstart == \"NA\" and not pd.isnull(row.CDS_start):\n",
    "            # 3'UTR\n",
    "            feature = \"3UTR_Length\"\n",
    "            start = int(CDSend) + 1\n",
    "            end = lengthTranscript\n",
    "            desc = \"ID=3UTR_Length;Name=3UTR_Length;Desc=3UTR_Length\\n\"\n",
    "            i += 1\n",
    "            res[i] = {\n",
    "                \"seqname\": transcript,\n",
    "                \"source\": sourceAux,\n",
    "                \"feature\": feature,\n",
    "                \"start\": str(int(start)),\n",
    "                \"end\": str(int(end)),\n",
    "                \"score\": aux,\n",
    "                \"strand\": strand,\n",
    "                \"frame\": aux,\n",
    "                \"attribute\": desc,\n",
    "            }\n",
    "\n",
    "            # 5'UTR\n",
    "            feature = \"5UTR_Length\"\n",
    "            start = 1\n",
    "            end = int(row.CDS_start) - 1 + 1  # 30\n",
    "            desc = \"ID=5UTR_Length;Name=5UTR_Length;Desc=5UTR_Length\\n\"\n",
    "            i += 1\n",
    "            res[i] = {\n",
    "                \"seqname\": transcript,\n",
    "                \"source\": sourceAux,\n",
    "                \"feature\": feature,\n",
    "                \"start\": str(int(start)),\n",
    "                \"end\": str(int(end)),\n",
    "                \"score\": aux,\n",
    "                \"strand\": strand,\n",
    "                \"frame\": aux,\n",
    "                \"attribute\": desc,\n",
    "            }\n",
    "\n",
    "            # CDS\n",
    "            feature = \"CDS\"\n",
    "            start = CDSstart\n",
    "            end = CDSend\n",
    "            desc = \"ID=CDS;Name=CDS;Desc=CDS\\n\"\n",
    "            i += 1\n",
    "            res[i] = {\n",
    "                \"seqname\": transcript,\n",
    "                \"source\": sourceAux,\n",
    "                \"feature\": feature,\n",
    "                \"start\": str(int(start)),\n",
    "                \"end\": str(int(end)),\n",
    "                \"score\": aux,\n",
    "                \"strand\": strand,\n",
    "                \"frame\": aux,\n",
    "                \"attribute\": desc,\n",
    "            }\n",
    "\n",
    "            # polyA\n",
    "            feature = \"polyA_Site\"\n",
    "            start = lengthTranscript\n",
    "            end = lengthTranscript\n",
    "            desc = \"ID=polyA_Site;Name=polyA_Site;Desc=polyA_Site\\n\"\n",
    "            i += 1\n",
    "            res[i] = {\n",
    "                \"seqname\": transcript,\n",
    "                \"source\": sourceAux,\n",
    "                \"feature\": feature,\n",
    "                \"start\": start,\n",
    "                \"end\": end,\n",
    "                \"score\": aux,\n",
    "                \"strand\": strand,\n",
    "                \"frame\": aux,\n",
    "                \"attribute\": desc,\n",
    "            }\n",
    "\n",
    "    # add exons\n",
    "    logger.debug(f\"reading exon file {exons_gtf}\")\n",
    "    exons_df = gtfparse.parse_gtf(exons_gtf)\n",
    "\n",
    "    for row in tqdm(exons_df.itertuples(), total=len(exons_df)):\n",
    "        transcript = row.transcript_id\n",
    "        # source\n",
    "        feature = row.feature\n",
    "        if feature == \"transcript\":  # just want exons\n",
    "            continue\n",
    "\n",
    "        start = row.start\n",
    "        end = row.end\n",
    "        # aux\n",
    "        strand = row.strand\n",
    "        # desc = fields[8]\n",
    "        desc = f\"Chr={str(row.seqname)}{NEWLINE}\"\n",
    "\n",
    "        # Exons Dictionary\n",
    "        i += 1\n",
    "        res[i] = {\n",
    "            \"seqname\": transcript,\n",
    "            \"source\": source,\n",
    "            \"feature\": feature,\n",
    "            \"start\": str(int(start)),\n",
    "            \"end\": str(int(end)),\n",
    "            \"score\": aux,\n",
    "            \"strand\": strand,\n",
    "            \"frame\": aux,\n",
    "            \"attribute\": desc,\n",
    "        }\n",
    "\n",
    "    # add junctions\n",
    "    logger.debug(f\"reading junctions file {junctions}\")\n",
    "    junct_df = pd.read_csv(junctions, delimiter=\"\\t\")\n",
    "    # header\n",
    "    for row in tqdm(junct_df.itertuples(), total=len(junct_df)):\n",
    "        transcript = row.isoform\n",
    "        # source\n",
    "        feature = \"splice_junction\"\n",
    "        start = row.genomic_start_coord\n",
    "        end = row.genomic_end_coord\n",
    "        # aux\n",
    "        strand = row.strand\n",
    "        desc = f\"ID={row.junction_number}_{row.canonical};Chr={row.chrom}{NEWLINE}\"\n",
    "        i += 1\n",
    "        res[i] = {\n",
    "            \"seqname\": transcript,\n",
    "            \"source\": source,\n",
    "            \"feature\": feature,\n",
    "            \"start\": str(int(start)),\n",
    "            \"end\": str(int(end)),\n",
    "            \"score\": aux,\n",
    "            \"strand\": strand,\n",
    "            \"frame\": aux,\n",
    "            \"attribute\": desc,\n",
    "        }\n",
    "\n",
    "    logger.debug(f\"length of dictionary: {len(res)}\")\n",
    "    logger.debug(\"converting dictionary to dataframe\")\n",
    "    results_df = pd.DataFrame.from_dict(\n",
    "        res,\n",
    "        orient=\"index\",\n",
    "        columns=[\n",
    "            \"seqname\",\n",
    "            \"source\",\n",
    "            \"feature\",\n",
    "            \"start\",\n",
    "            \"end\",\n",
    "            \"score\",\n",
    "            \"strand\",\n",
    "            \"frame\",\n",
    "            \"attribute\",\n",
    "        ],\n",
    "    )\n",
    "    results_df[\"attribute\"] = results_df[\"attribute\"].apply(lambda x: x.rstrip(\"\\n\"))\n",
    "    logger.debug(f\"results_df shape: {results_df.shape}\")\n",
    "    return results_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def createGTFFromSqanti(file_exons, file_trans, file_junct, filename):\n",
    "    res = open(filename, \"w+\")\n",
    "    source = \"tappAS\"\n",
    "    feature = \"\"\n",
    "    start = \"\"\n",
    "    end = \"\"\n",
    "    aux = \".\"\n",
    "    strand = \"\"\n",
    "    desc = \"\"\n",
    "\n",
    "    dc_coding = {}\n",
    "    dc_gene = {}\n",
    "    dc_SQstrand = {}\n",
    "    f = open(file_trans)\n",
    "\n",
    "    # check header\n",
    "    global CLASS_COLUMN_USED\n",
    "    global CLASS_COLUMN_NAME\n",
    "\n",
    "    header = next(f)\n",
    "    fields = header.split(\"\\t\")\n",
    "    index = 0\n",
    "    for column in CLASS_COLUMN_NAME:  # check all the columns we used\n",
    "        if (\n",
    "            column not in fields[CLASS_COLUMN_USED[index]]\n",
    "        ):  # if now in the correct possition...\n",
    "            logging.info(\n",
    "                f\"File classification does not have the correct structure. \"\n",
    "                f\" The column '{column}' is not in the possition \"\n",
    "                f\"{str(CLASS_COLUMN_USED[index])}\"\n",
    "                f\" in the classification file. We have found the column '\"\n",
    "                f\"{str(fields[CLASS_COLUMN_USED[index]])}'.\"\n",
    "            )\n",
    "            sys.exit()\n",
    "        else:\n",
    "            index = index + 1\n",
    "\n",
    "    # add transcript, gene and CDS\n",
    "    for line in f:\n",
    "        fields = line.split(\"\\t\")\n",
    "\n",
    "        # trans\n",
    "        transcript = fields[0]\n",
    "        # source\n",
    "        feature = \"transcript\"\n",
    "        start = \"1\"\n",
    "        end = fields[3]\n",
    "        # aux\n",
    "        strand = fields[2]\n",
    "\n",
    "        dc_SQstrand.update({str(transcript): strand})  # saving strand\n",
    "\n",
    "        desc = \"ID=\" + fields[7] + \"; primary_class=\" + fields[5] + \"\\n\"\n",
    "        res.write(\n",
    "            \"\\t\".join([transcript, source, feature, start, end, aux, strand, aux, desc])\n",
    "        )\n",
    "        # gene\n",
    "        transcript = fields[0]\n",
    "        # source\n",
    "        feature = \"gene\"\n",
    "        start = \"1\"\n",
    "        end = fields[3]\n",
    "        # aux\n",
    "        strand = fields[2]\n",
    "        desc = \"ID=\" + fields[6] + \"; Name=\" + fields[6] + \"; Desc=\" + fields[6] + \"\\n\"\n",
    "        res.write(\n",
    "            \"\\t\".join([transcript, source, feature, start, end, aux, strand, aux, desc])\n",
    "        )\n",
    "        # CDS\n",
    "        transcript = fields[0]\n",
    "        # source\n",
    "        feature = \"CDS\"\n",
    "        start = fields[30]  # 30\n",
    "        end = fields[31]  # 31\n",
    "        # aux\n",
    "        strand = fields[2]\n",
    "        desc = (\n",
    "            \"ID=Protein_\"\n",
    "            + transcript\n",
    "            + \"; Name=Protein_\"\n",
    "            + transcript\n",
    "            + \"; Desc=Protein_\"\n",
    "            + transcript\n",
    "            + \"\\n\"\n",
    "        )\n",
    "        if start != \"NA\":\n",
    "            res.write(\n",
    "                \"\\t\".join(\n",
    "                    [transcript, source, feature, start, end, aux, strand, aux, desc]\n",
    "                )\n",
    "            )\n",
    "            res.write(\n",
    "                \"\\t\".join(\n",
    "                    [\n",
    "                        transcript,\n",
    "                        source,\n",
    "                        \"protein\",\n",
    "                        \"1\",\n",
    "                        str(int(math.ceil((int(end) - int(start) - 1) / 3))),\n",
    "                        aux,\n",
    "                        strand,\n",
    "                        aux,\n",
    "                        desc,\n",
    "                    ]\n",
    "                )\n",
    "            )\n",
    "        else:\n",
    "            res.write(\n",
    "                \"\\t\".join(\n",
    "                    [transcript, source, feature, \".\", \".\", aux, strand, aux, desc]\n",
    "                )\n",
    "            )\n",
    "        # genomic\n",
    "        desc = \"Chr=\" + fields[1] + \"\\n\"\n",
    "\n",
    "        # Gene\n",
    "        gene = fields[6]\n",
    "        category = fields[5]\n",
    "        transAssociated = fields[7]\n",
    "\n",
    "        if transAssociated.startswith(\"ENS\"):\n",
    "            transAssociated = transAssociated.split(\n",
    "                \".\"\n",
    "            )  # ENSMUS213123.1 -> #ENSMUS213123\n",
    "            transAssociated = transAssociated[0]\n",
    "\n",
    "        if not dc_gene.get(transcript):\n",
    "            dc_gene.update({str(transcript): [gene, category, transAssociated]})\n",
    "        else:\n",
    "            dc_gene.update(\n",
    "                {\n",
    "                    str(transcript): dc_gene.get(transcript)\n",
    "                    + [gene, category, transAssociated]\n",
    "                }\n",
    "            )\n",
    "\n",
    "        # Coding Dictionary\n",
    "        CDSstart = fields[30]  # 30\n",
    "        CDSend = fields[31]  # 31\n",
    "        orf = fields[28]  # 28\n",
    "\n",
    "        if not dc_coding.get(transcript):\n",
    "            dc_coding.update({str(transcript): [CDSstart, CDSend, orf]})\n",
    "        else:\n",
    "            dc_coding.update(\n",
    "                {str(transcript): dc_coding.get(transcript) + [CDSstart, CDSend, orf]}\n",
    "            )\n",
    "\n",
    "        res.write(\n",
    "            \"\\t\".join([transcript, source, \"genomic\", \"1\", \"1\", aux, strand, aux, desc])\n",
    "        )\n",
    "\n",
    "        # Write TranscriptAttributes\n",
    "        sourceAux = \"TranscriptAttributes\"\n",
    "        lengthTranscript = fields[3]\n",
    "        if not CDSstart == \"NA\":\n",
    "            # 3'UTR\n",
    "            feature = \"3UTR_Length\"\n",
    "            start = int(CDSend) + 1\n",
    "            end = lengthTranscript\n",
    "            desc = \"ID=3UTR_Length; Name=3UTR_Length; Desc=3UTR_Length\\n\"\n",
    "            res.write(\n",
    "                \"\\t\".join(\n",
    "                    [\n",
    "                        transcript,\n",
    "                        sourceAux,\n",
    "                        feature,\n",
    "                        str(start),\n",
    "                        str(end),\n",
    "                        aux,\n",
    "                        strand,\n",
    "                        aux,\n",
    "                        desc,\n",
    "                    ]\n",
    "                )\n",
    "            )\n",
    "            # 5'UTR\n",
    "            feature = \"5UTR_Length\"\n",
    "            start = 1\n",
    "            end = int(fields[30]) - 1 + 1  # 30\n",
    "            desc = \"ID=5UTR_Length; Name=5UTR_Length; Desc=5UTR_Length\\n\"\n",
    "            res.write(\n",
    "                \"\\t\".join(\n",
    "                    [\n",
    "                        transcript,\n",
    "                        sourceAux,\n",
    "                        feature,\n",
    "                        str(start),\n",
    "                        str(end),\n",
    "                        aux,\n",
    "                        strand,\n",
    "                        aux,\n",
    "                        desc,\n",
    "                    ]\n",
    "                )\n",
    "            )\n",
    "            # CDS\n",
    "            feature = \"CDS\"\n",
    "            start = CDSstart\n",
    "            end = CDSend\n",
    "            desc = \"ID=CDS; Name=CDS; Desc=CDS\\n\"\n",
    "            res.write(\n",
    "                \"\\t\".join(\n",
    "                    [\n",
    "                        transcript,\n",
    "                        sourceAux,\n",
    "                        feature,\n",
    "                        str(start),\n",
    "                        str(end),\n",
    "                        aux,\n",
    "                        strand,\n",
    "                        aux,\n",
    "                        desc,\n",
    "                    ]\n",
    "                )\n",
    "            )\n",
    "            # polyA\n",
    "            feature = \"polyA_Site\"\n",
    "            start = lengthTranscript\n",
    "            end = lengthTranscript\n",
    "            desc = \"ID=polyA_Site; Name=polyA_Site; Desc=polyA_Site\\n\"\n",
    "            res.write(\n",
    "                \"\\t\".join(\n",
    "                    [\n",
    "                        transcript,\n",
    "                        sourceAux,\n",
    "                        feature,\n",
    "                        str(start),\n",
    "                        str(end),\n",
    "                        aux,\n",
    "                        strand,\n",
    "                        aux,\n",
    "                        desc,\n",
    "                    ]\n",
    "                )\n",
    "            )\n",
    "\n",
    "    f.close()\n",
    "\n",
    "    f = open(file_exons)\n",
    "    dc_exons = {}\n",
    "    # add exons\n",
    "    for line in f:\n",
    "        fields = line.split(\"\\t\")\n",
    "        if len(fields) == 9:\n",
    "            transcript = fields[8].split('\"')[1].strip()\n",
    "            # source\n",
    "            feature = fields[2]\n",
    "            if feature == \"transcript\":  # just want exons\n",
    "                continue\n",
    "\n",
    "            start = int(fields[3])\n",
    "            end = int(fields[4])\n",
    "            # aux\n",
    "            strand = fields[6]\n",
    "            # desc = fields[8]\n",
    "            desc = \"Chr=\" + str(fields[0]) + \"\\n\"\n",
    "\n",
    "            # Exons Dictionary\n",
    "            if not dc_exons.get(transcript):\n",
    "                dc_exons.update({str(transcript): [[start, end]]})\n",
    "            else:\n",
    "                dc_exons.update(\n",
    "                    {str(transcript): dc_exons.get(transcript) + [[start, end]]}\n",
    "                )\n",
    "\n",
    "            res.write(\n",
    "                \"\\t\".join(\n",
    "                    [\n",
    "                        transcript,\n",
    "                        source,\n",
    "                        feature,\n",
    "                        str(start),\n",
    "                        str(end),\n",
    "                        aux,\n",
    "                        strand,\n",
    "                        aux,\n",
    "                        desc,\n",
    "                    ]\n",
    "                )\n",
    "            )\n",
    "        else:\n",
    "            logging.error(\n",
    "                \"File corrected doesn't have the correct number of columns (9).\"\n",
    "            )\n",
    "    f.close()\n",
    "\n",
    "    # add junctions\n",
    "    f = open(file_junct)\n",
    "    # header\n",
    "    header = next(f)\n",
    "    for line in f:\n",
    "        fields = line.split(\"\\t\")\n",
    "        # Junctions file can have a dvierse number of columns, not only 19 but 0-14 are allways the same\n",
    "        transcript = fields[0]\n",
    "        # source\n",
    "        feature = \"splice_junction\"\n",
    "        start = fields[4]\n",
    "        end = fields[5]\n",
    "        # aux\n",
    "        strand = fields[2]\n",
    "        desc = \"ID=\" + fields[3] + \"_\" + fields[14] + \"; Chr=\" + fields[1] + \"\\n\"\n",
    "\n",
    "        res.write(\n",
    "            \"\\t\".join([transcript, source, feature, start, end, aux, strand, aux, desc])\n",
    "        )\n",
    "    f.close()\n",
    "    res.close()\n",
    "\n",
    "    return dc_exons, dc_coding, dc_gene, dc_SQstrand\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readGFFandGetData(filenameMod):\n",
    "    # open annotation file and process all data\n",
    "    dcTrans = {}\n",
    "    dcExon = {}\n",
    "    dcTransFeatures = {}\n",
    "    dcGenomic = {}\n",
    "    dcSpliceJunctions = {}\n",
    "    dcProt = {}\n",
    "    dcProtFeatures = {}\n",
    "    dcTranscriptAttributes = {}\n",
    "\n",
    "    # dcTransID = {}\n",
    "\n",
    "    with open(filenameMod, \"r\") as f:\n",
    "        # process all entries - no header line in file\n",
    "        for line in f:\n",
    "            if len(line) == 0:\n",
    "                break\n",
    "            else:\n",
    "                if line and line[0] != \"#\":\n",
    "                    fields = line.split(\"\\t\")\n",
    "                    if len(fields) == 9:\n",
    "\n",
    "                        transcript = fields[0]\n",
    "                        text = fields[8].split(\" \")\n",
    "                        # transcriptID = text[0]\n",
    "                        # transcriptID = transcriptID[3:-1]\n",
    "\n",
    "                        if fields[1] == \"tappAS\":\n",
    "                            if fields[2] in [\"transcript\", \"gene\", \"CDS\"]:\n",
    "                                if not dcTrans.get(str(transcript)):\n",
    "                                    dcTrans.update({str(transcript): [line]})\n",
    "                                else:\n",
    "                                    dcTrans.update(\n",
    "                                        {\n",
    "                                            str(transcript): dcTrans.get(\n",
    "                                                str(transcript)\n",
    "                                            )\n",
    "                                            + [line]\n",
    "                                        }\n",
    "                                    )\n",
    "                                # extra dcTransID\n",
    "                                # if not dcTransID.get(str(transcriptID)):\n",
    "                                #    dcTransID.update({str(transcriptID) : [line]})\n",
    "                                # else:\n",
    "                                #    dcTransID.update({str(transcriptID) : dcTransID.get(str(transcriptID)) + [line]})\n",
    "                            elif fields[2] in [\"exon\"]:\n",
    "                                if not dcExon.get(str(transcript)):\n",
    "                                    dcExon.update({str(transcript): [line]})\n",
    "                                else:\n",
    "                                    dcExon.update(\n",
    "                                        {\n",
    "                                            str(transcript): dcExon.get(str(transcript))\n",
    "                                            + [line]\n",
    "                                        }\n",
    "                                    )\n",
    "                            elif fields[2] in [\"genomic\"]:\n",
    "                                if not dcGenomic.get(str(transcript)):\n",
    "                                    dcGenomic.update({str(transcript): [line]})\n",
    "                                else:\n",
    "                                    dcGenomic.update(\n",
    "                                        {\n",
    "                                            str(transcript): dcGenomic.get(\n",
    "                                                str(transcript)\n",
    "                                            )\n",
    "                                            + [line]\n",
    "                                        }\n",
    "                                    )\n",
    "                            elif fields[2] in [\"splice_junction\"]:\n",
    "                                if not dcSpliceJunctions.get(str(transcript)):\n",
    "                                    dcSpliceJunctions.update({str(transcript): [line]})\n",
    "                                else:\n",
    "                                    dcSpliceJunctions.update(\n",
    "                                        {\n",
    "                                            str(transcript): dcSpliceJunctions.get(\n",
    "                                                str(transcript)\n",
    "                                            )\n",
    "                                            + [line]\n",
    "                                        }\n",
    "                                    )\n",
    "                            elif fields[2] in [\"protein\"]:\n",
    "                                if not dcProt.get(str(transcript)):\n",
    "                                    dcProt.update({str(transcript): [line]})\n",
    "                                else:\n",
    "                                    dcProt.update(\n",
    "                                        {\n",
    "                                            str(transcript): dcProt.get(str(transcript))\n",
    "                                            + [line]\n",
    "                                        }\n",
    "                                    )\n",
    "                        # Transcript Information\n",
    "                        elif fields[1] == \"TranscriptAttributes\":\n",
    "                            if not dcTranscriptAttributes.get(str(transcript)):\n",
    "                                dcTranscriptAttributes.update({str(transcript): [line]})\n",
    "                            else:\n",
    "                                dcTranscriptAttributes.update(\n",
    "                                    {\n",
    "                                        str(transcript): dcTranscriptAttributes.get(\n",
    "                                            str(transcript)\n",
    "                                        )\n",
    "                                        + [line]\n",
    "                                    }\n",
    "                                )\n",
    "                        # Feature information\n",
    "                        else:\n",
    "                            if text[-1].endswith(\"T\\n\"):\n",
    "                                if not dcTransFeatures.get(str(transcript)):\n",
    "                                    dcTransFeatures.update({str(transcript): [line]})\n",
    "                                else:\n",
    "                                    dcTransFeatures.update(\n",
    "                                        {\n",
    "                                            str(transcript): dcTransFeatures.get(\n",
    "                                                str(transcript)\n",
    "                                            )\n",
    "                                            + [line]\n",
    "                                        }\n",
    "                                    )\n",
    "                            elif (\n",
    "                                text[-1].endswith(\"P\\n\")\n",
    "                                or text[-1].endswith(\"G\\n\")\n",
    "                                or text[-1].endswith(\"N\\n\")\n",
    "                            ):\n",
    "                                if not dcProtFeatures.get(str(transcript)):\n",
    "                                    dcProtFeatures.update({str(transcript): [line]})\n",
    "                                else:\n",
    "                                    dcProtFeatures.update(\n",
    "                                        {\n",
    "                                            str(transcript): dcProtFeatures.get(\n",
    "                                                str(transcript)\n",
    "                                            )\n",
    "                                            + [line]\n",
    "                                        }\n",
    "                                    )\n",
    "\n",
    "    return (\n",
    "        dcTrans,\n",
    "        dcExon,\n",
    "        dcTransFeatures,\n",
    "        dcGenomic,\n",
    "        dcSpliceJunctions,\n",
    "        dcProt,\n",
    "        dcProtFeatures,\n",
    "        dcTranscriptAttributes,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "annot_tpl = readGFFandGetData(annotation_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "188667"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(annot_df[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "188667"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(annot_df[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(annot_df[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "124947"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(annot_df[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "79641"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(annot_df[6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ENST00000618881\\tGeneOntology\\tP\\t.\\t.\\t.\\t.\\t.\\tID=GO:0006810; Name=transport; PosType=N\\n',\n",
       " 'ENST00000618881\\tGeneOntology\\tC\\t.\\t.\\t.\\t.\\t.\\tID=GO:0005622; Name=intracellular; PosType=N\\n',\n",
       " 'ENST00000618881\\tGeneOntology\\tC\\t.\\t.\\t.\\t.\\t.\\tID=GO:0005737; Name=cytoplasm; PosType=N\\n',\n",
       " 'ENST00000618881\\tGeneOntology\\tP\\t.\\t.\\t.\\t.\\t.\\tID=GO:0006406; Name=mRNA export from nucleus; PosType=N\\n',\n",
       " 'ENST00000618881\\tGeneOntology\\tC\\t.\\t.\\t.\\t.\\t.\\tID=GO:0005634; Name=nucleus; PosType=N\\n',\n",
       " 'ENST00000618881\\tGeneOntology\\tF\\t.\\t.\\t.\\t.\\t.\\tID=GO:0003723; Name=RNA binding; PosType=N\\n',\n",
       " 'ENST00000618881\\tGeneOntology\\tF\\t.\\t.\\t.\\t.\\t.\\tID=GO:0005515; Name=protein binding; PosType=N\\n',\n",
       " 'ENST00000618881\\tGeneOntology\\tF\\t.\\t.\\t.\\t.\\t.\\tID=GO:0003676; Name=nucleic acid binding; PosType=N\\n',\n",
       " 'ENST00000618881\\tReactome\\tpathway\\t.\\t.\\t.\\t.\\t.\\tID=R-HSA-159236; Name=Transport of Mature mRNA derived from an Intron-Containing Transcript; PosType=N\\n',\n",
       " 'ENST00000618881\\tPFAM\\tDOMAIN\\t304\\t334\\t.\\t.\\t.\\tID=PF02136; Name=NTF2; Desc=Nuclear transport factor 2 (NTF2) domain; PosType=P\\n',\n",
       " 'ENST00000618881\\tPFAM\\tCLAN\\t.\\t.\\t.\\t.\\t.\\tID=CL0051; Name=NTF2; Desc=NTF2-like superfamily; PosType=N\\n',\n",
       " 'ENST00000618881\\tPFAM\\tDOMAIN\\t34\\t115\\t.\\t.\\t.\\tID=PF09162; Name=Tap-RNA_bind; Desc=Tap, RNA-binding; PosType=P\\n',\n",
       " 'ENST00000618881\\tPFAM\\tCLAN\\t.\\t.\\t.\\t.\\t.\\tID=CL0221; Name=RRM; Desc=RRM-like clan; PosType=N\\n',\n",
       " 'ENST00000618881\\tUniProtKB/Swiss-Prot_Phosphosite\\tPTM\\t115\\t115\\t.\\t.\\t.\\tID=Phosphotyrosine; Name=Phosphotyrosine; Desc=Phosphotyrosine_PhosphositePlus; PosType=P\\n',\n",
       " 'ENST00000618881\\tUniProtKB/Swiss-Prot_Phosphosite\\tPTM\\t295\\t295\\t.\\t.\\t.\\tID=Phosphothreonine; Name=Phosphothreonine; Desc=Phosphothreonine_PhosphositePlus; PosType=P\\n',\n",
       " 'ENST00000618881\\tUniProtKB/Swiss-Prot_Phosphosite\\tPTM\\t32\\t32\\t.\\t.\\t.\\tID=Phosphotyrosine; Name=Phosphotyrosine; Desc=Phosphotyrosine_PhosphositePlus; PosType=P\\n',\n",
       " 'ENST00000618881\\tUniProtKB/Swiss-Prot_Phosphosite\\tPTM\\t97\\t97\\t.\\t.\\t.\\tID=Phosphotyrosine; Name=Phosphotyrosine; Desc=Phosphotyrosine_PhosphositePlus; PosType=P\\n']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annot_df[6]['ENST00000618881']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
